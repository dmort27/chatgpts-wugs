{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Workers = 16\n",
    "\n",
    "\n",
    "# Lang = 'eng'\n",
    "# Number_of_parts = 200\n",
    "# MaxVar = 1\n",
    "\n",
    "# Lang = 'deu'\n",
    "# Number_of_parts = 1000\n",
    "# MaxVar = 1\n",
    "\n",
    "Lang = 'tur'\n",
    "Number_of_parts = 1000\n",
    "MaxVar = 1\n",
    "\n",
    "\n",
    "# Lang = 'tam'\n",
    "# Number_of_parts = 1000\n",
    "# MaxVar = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1\n",
    "\n",
    "Coding of the diphones on a character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Corresp_deu = [('aː', 'A'),\n",
    "#             ('ai̯', 'B'),\n",
    "#             ('au̯', 'C'),\n",
    "#             ('dʒ', 'D'),\n",
    "#             ('eːə', 'E'),\n",
    "#             ('eː', 'F'),\n",
    "#             ('ɛːə', 'G'),\n",
    "#             ('ɛː', 'H'),\n",
    "#             ('iːə', 'I'),\n",
    "#             ('iː', 'J'),\n",
    "#             ('oː', 'K'),\n",
    "#             ('øː', 'L'),\n",
    "#             ('œ', 'M'),\n",
    "#             ('oi̯', 'N'),\n",
    "#             ('pf', 'O'),\n",
    "#             ('ts', 'P'),\n",
    "#             ('tʃ', 'Q'),\n",
    "#             ('uː', 'R'),\n",
    "#             ('yː', 'S'),\n",
    "#             ('ɡ', 'g'),\n",
    "#             (' ', '')]\n",
    "\n",
    "Corresp_eng =  [('aɪ', 'A'),\n",
    "            ('aʊ', 'B'),\n",
    "            ('ɑː', 'C'),\n",
    "            ('eɪ', 'D'),\n",
    "            ('əː', 'E'),\n",
    "            ('əʊ', 'F'),\n",
    "            ('ɜː', 'G'),\n",
    "            ('iː', 'H'),\n",
    "            ('l̩ˠ', 'l'),\n",
    "            ('lˠ', 'l'),\n",
    "            ('m̩', 'm'),\n",
    "            ('n̩', 'n'),\n",
    "            ('ŋ̍', 'ŋ'),\n",
    "            ('ɔ̃ː', 'I'),\n",
    "            ('ɔː', 'J'),\n",
    "            ('ɔɪ', 'K'),\n",
    "            ('uːɪ', 'L'),\n",
    "            ('uː', 'M')]\n",
    "\n",
    "# Corresp_nld =  [('aː', 'A'),\n",
    "#             ('ɑʊ', 'B'),\n",
    "#             ('eː', 'C'),\n",
    "#             ('ɛː', 'D'),\n",
    "#             ('ɛɪ', 'E'),\n",
    "#             ('iː', 'F'),\n",
    "#             ('oː', 'G'),\n",
    "#             ('ɔː', 'H'),\n",
    "#             ('uː', 'I'),\n",
    "#             ('ʊɪ', 'J'),\n",
    "#             ('yː', 'K'),\n",
    "#             ('ɡ', 'g'),\n",
    "#             (' ', '')]\n",
    "\n",
    "# Corresp_all = {'eng': Corresp_eng, 'nld': Corresp_nld, 'deu': Corresp_deu}\n",
    "# Corresp = sorted(Corresp_all[Lang], reverse=True, key=lambda x: len(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Corresp_eng = [('æ', 'A'),\n",
    "#                ('ɛ', 'B'),\n",
    "#                ('ɪ', 'C'),\n",
    "#                ('ɑ', 'D'),\n",
    "#                ('ɔ', 'E'),\n",
    "#                ('ʌ', 'F'),\n",
    "#                ('ə', 'G'),\n",
    "#                ('ʊ', 'H'),\n",
    "#                ('ɹ̩', 'I'),\n",
    "#                ('t͡ʃ', 'J'),\n",
    "#                ('ɾ', 'K'),\n",
    "#                ('ɡ', 'L'),\n",
    "#                ('d͡ʒ', 'M'),\n",
    "#                ('m̩', 'N'),\n",
    "#                ('n̩', 'O'),\n",
    "#                ('ŋ', 'P'),\n",
    "#                ('ʔ', 'Q'),\n",
    "#                ('ɹ', 'R'),\n",
    "#                ('ʃ', 'S'),\n",
    "#                ('ð', 'T'),\n",
    "#                ('ʒ', 'U')]\n",
    "\n",
    "Corresp_deu = [('d͡ʒ', 'A'),\n",
    "               ('ç', 'B'),\n",
    "               ('ŋ', 'C'),\n",
    "               ('p͡f', 'D'),\n",
    "               ('ʀ', 'E'),\n",
    "               ('ʃ', 'F'),\n",
    "               ('t͡ʃ', 'G'),\n",
    "               ('t͡s', 'H'),\n",
    "               ('æ', 'I'),\n",
    "               ('ø', 'J'),\n",
    "               ('ə', 'K'),\n",
    "               ('ɪ', 'L'),\n",
    "               ('ʏ', 'M'),\n",
    "               ('ɛ', 'N'),\n",
    "               ('œ', 'O'),\n",
    "               ('ɔ', 'P'),\n",
    "               ('ɐ', 'Q')]\n",
    "\n",
    "Corresp_tur = [('d͡ʒ', 'A'),\n",
    "               ('t͡ʃ', 'B'),\n",
    "               ('ɡ', 'C'),\n",
    "               ('ɰ', 'D'),\n",
    "               ('ɯ', 'E'),\n",
    "               ('ʒ', 'F'),\n",
    "               ('œ', 'G'),\n",
    "               ('ɾ', 'H'),\n",
    "               ('ʃ', 'I')]\n",
    "\n",
    "Corresp_tam = [('t͡ʃ', 'A'),\n",
    "               ('ɲ', 'B'),\n",
    "               ('ʈ', 'C'),\n",
    "               ('ɳ', 'D'),\n",
    "               ('t̪', 'E'),\n",
    "               ('n̪', 'F'),\n",
    "               ('ɾ', 'G'),\n",
    "               ('ʋ', 'H'),\n",
    "               ('ɻ', 'I'),\n",
    "               ('ɭ', 'J'),\n",
    "               ('d͡ʒ', 'K'),\n",
    "               ('ʂ', 'L'),\n",
    "               ('aː', 'M'),\n",
    "               ('iː', 'N'),\n",
    "               ('uː', 'O'),\n",
    "               ('eː', 'P'),\n",
    "               ('oː', 'Q'),\n",
    "               ('aʋ', 'R')]\n",
    "\n",
    "Corresp_all = {'eng': Corresp_eng, 'tur': Corresp_tur, 'deu': Corresp_deu, 'tam': Corresp_tam}\n",
    "Corresp = sorted(Corresp_all[Lang], reverse=True, key=lambda x: len(x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shortening of tags with features that are not associated with formal variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduced_tag(Tag):\n",
    "    '''\n",
    "    Some English tags are not associated with formal variatiions\n",
    "    '''\n",
    "    \n",
    "    if Tag in ['V;PRS;3;SG', 'V.PTCP;PRS', 'V.PTCP;PST']:\n",
    "        return(Tag)\n",
    "    if Tag.startswith('V;PRS'):\n",
    "        return('V;NINF')\n",
    "    if Tag.startswith('V;PST'):\n",
    "        return('V;PST')\n",
    "    return(Tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Particle inversion (German, Dutch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import regex\n",
    "\n",
    "def invert_particle(Form):\n",
    "    '''\n",
    "    Dutch and German particles appear in different positions in inflected and infinitive forms.\n",
    "    '''\n",
    "    if Form.count('+') == 1:\n",
    "        return(regex.subf(\"^([^+]+)\\+([^+]+)$\", \"{2}{1}\", Form).lower())\n",
    "    if Form.count('+') == 2:\n",
    "        print('2 +', Form)\n",
    "        return(regex.subf(\"^([^+]+)\\+([^+]+)\\+([^+]+)$\", \"{2}{3}{1}\", Form).lower())\n",
    "    if Form.count('+') > 2:\n",
    "        print('3+ +', Form)\n",
    "        return\n",
    "    return(Form.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recording of the correspondence between the data in the format provided by the task organizers and the format used for FAP computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "OutFileName = f'../data/{Lang}/steps_new/{Lang}.all.phono.pairs'\n",
    "OutFile = open(OutFileName, 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "InFileName1 = f'../../../data/{Lang}/{Lang}_IPA.trn'\n",
    "InFile1 = open(InFileName1)\n",
    "\n",
    "OutFileName1 = f'../data/{Lang}/steps_new/{Lang}.trn.phono.pairs'\n",
    "OutFile1 = open(OutFileName1, 'w')\n",
    "\n",
    "for Line in InFile1:\n",
    "    (PhonoLem, PhonoForm, Tag, _OrthoLem, _OrthoForm) = Line.rstrip('\\n').split('\\t')\n",
    "    PhonoLem = invert_particle(PhonoLem)\n",
    "    PhonoForm = invert_particle(PhonoForm)\n",
    "    for P1, P2 in Corresp:\n",
    "        PhonoLem = PhonoLem.replace(P1, P2)\n",
    "        PhonoForm = PhonoForm.replace(P1, P2)\n",
    "    PhonoLem = PhonoLem.replace(' ', '')\n",
    "    PhonoForm = PhonoForm.replace(' ', '')\n",
    "    RedTag = reduced_tag(Tag) if Lang == 'eng' else Tag\n",
    "    OutFile1.write('{}\\t{}\\t{}\\t{}\\n'.format(Line.rstrip('\\n'), PhonoLem, PhonoForm, RedTag))\n",
    "    if RedTag == 'V;NFIN':\n",
    "        continue\n",
    "    OutFile.write(f'{PhonoLem}=V;NFIN\\t{PhonoForm}={RedTag}\\n')\n",
    "InFile1.close()\n",
    "OutFile1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "InFileName2 = f'../../../data/{Lang}/{Lang}_IPA.dev'\n",
    "InFile2 = open(InFileName2)\n",
    "\n",
    "OutFileName2 = f'../data/{Lang}/steps_new/{Lang}.dev.phono.pairs'\n",
    "OutFile2 = open(OutFileName2, 'w')\n",
    "\n",
    "for Line in InFile2:\n",
    "    (PhonoLem, PhonoForm, Tag, _OrthoLem, _OrthoForm) = Line.rstrip('\\n').split('\\t')\n",
    "    PhonoLem = invert_particle(PhonoLem)\n",
    "    PhonoForm = invert_particle(PhonoForm)\n",
    "    for P1, P2 in Corresp:\n",
    "        PhonoLem = PhonoLem.replace(P1, P2)\n",
    "        PhonoForm = PhonoForm.replace(P1, P2)\n",
    "    PhonoLem = PhonoLem.replace(' ', '')\n",
    "    PhonoForm = PhonoForm.replace(' ', '')\n",
    "    RedTag = reduced_tag(Tag) if Lang == 'eng' else Tag\n",
    "    OutFile2.write('{}\\t{}\\t{}\\t{}\\n'.format(Line.rstrip('\\n'), PhonoLem, PhonoForm, RedTag))\n",
    "    if RedTag == 'V;NFIN':\n",
    "        continue\n",
    "    OutFile.write(f'{PhonoLem}=V;NFIN\\t{PhonoForm}={RedTag}\\n')\n",
    "InFile2.close()\n",
    "OutFile2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Lang != \"tam\":\n",
    "    InFileName4 = f'../../../data/{Lang}/{Lang}_IPA.tst'\n",
    "    InFile4 = open(InFileName4)\n",
    "    OutFileName4 = f'../data/{Lang}/steps_new/{Lang}.tst.phono.pairs'\n",
    "    OutFile4 = open(OutFileName4, 'w')\n",
    "\n",
    "    for Line in InFile4:\n",
    "        (PhonoLem, PhonoForm, Tag, _OrthoLem, _OrthoForm) = Line.rstrip('\\n').split('\\t')\n",
    "        PhonoLem = invert_particle(PhonoLem)\n",
    "        PhonoForm = invert_particle(PhonoForm)\n",
    "        for P1, P2 in Corresp:\n",
    "            PhonoLem = PhonoLem.replace(P1, P2)\n",
    "            PhonoForm = PhonoForm.replace(P1, P2)\n",
    "        PhonoLem = PhonoLem.replace(' ', '')\n",
    "        PhonoForm = PhonoForm.replace(' ', '')\n",
    "        RedTag = reduced_tag(Tag) if Lang == 'eng' else Tag\n",
    "        OutFile4.write('{}\\t{}\\t{}\\t{}\\n'.format(Line.rstrip('\\n'), PhonoLem, PhonoForm, RedTag))\n",
    "        if RedTag == 'V;NFIN':\n",
    "            continue\n",
    "        OutFile.write(f'{PhonoLem}=V;NFIN\\t{PhonoForm}={RedTag}\\n')\n",
    "    InFile4.close()\n",
    "    OutFile4.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "InFileName5 = f'../../../data/{Lang}/{Lang}_IPA.nonce'\n",
    "InFile5 = open(InFileName5)\n",
    "\n",
    "OutFileName5 = f'../data/{Lang}/steps_new/{Lang}.nonce_full.phono.pairs'\n",
    "OutFile5 = open(OutFileName5, 'w')\n",
    "\n",
    "for Line in InFile5:\n",
    "    (PhonoLem, PhonoForm, Tag, _OrthoLem, _OrthoForm) = Line.rstrip('\\n').split('\\t')\n",
    "    PhonoLem = invert_particle(PhonoLem)\n",
    "    PhonoForm = invert_particle(PhonoForm)\n",
    "    for P1, P2 in Corresp:\n",
    "        PhonoLem = PhonoLem.replace(P1, P2)\n",
    "        PhonoForm = PhonoForm.replace(P1, P2)\n",
    "    PhonoLem = PhonoLem.replace(' ', '')\n",
    "    PhonoForm = PhonoForm.replace(' ', '')\n",
    "    RedTag = reduced_tag(Tag) if Lang == 'eng' else Tag\n",
    "    OutFile5.write('{}\\t{}\\t{}\\t{}\\n'.format(Line.rstrip('\\n'), PhonoLem, PhonoForm, RedTag))\n",
    "    if RedTag == 'V;NFIN':\n",
    "        continue\n",
    "    OutFile.write(f'{PhonoLem}=V;NFIN\\t{PhonoForm}={RedTag}\\n')\n",
    "InFile5.close()\n",
    "OutFile5.close()\n",
    "OutFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['sort', '-u', '-o', '../data/tur/steps_new/tur.all.phono.pairs_sort_u', '../data/tur/steps_new/tur.all.phono.pairs'], returncode=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "my_env = {'LC_COLLATE':'C'}\n",
    "\n",
    "PairsFileIn = f'../data/{Lang}/steps_new/{Lang}.all.phono.pairs'\n",
    "PairsFileOut = f'../data/{Lang}/steps_new/{Lang}.all.phono.pairs_sort_u'\n",
    "\n",
    "subprocess.run(['sort', '-u', '-o', PairsFileOut, PairsFileIn], env=my_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Signatures computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import Levenshtein\n",
    "import collections\n",
    "\n",
    "PairsFileIn = open(f'../data/{Lang}/steps_new/{Lang}.all.phono.pairs_sort_u')\n",
    "SignaturesFileOut = open(f'../data/{Lang}/steps_new/{Lang}.all.phono.sign', 'w')\n",
    "\n",
    "for Line in PairsFileIn:\n",
    "    Word1, Word2 = Line.rstrip('\\n').split('\\t')\n",
    "    Lemme1, Cat1 = Word1.split('=')\n",
    "    Lemme2, Cat2 = Word2.split('=')\n",
    "    Dist = Levenshtein.distance(Lemme1, Lemme2, weights=(1,1,2))\n",
    "    Coll1 = collections.Counter(Lemme1)\n",
    "    Coll2 = collections.Counter(Lemme2)\n",
    "    Coll1.subtract(Coll2)\n",
    "    CharDiff = ':'.join(sorted([f'{Char}.{Count}' for Char, Count in Coll1.items() if Count]))\n",
    "    SignaturesFileOut.write(f'{Dist}\\t{CharDiff}\\t{Word1}\\t{Word2}\\n')\n",
    "\n",
    "SignaturesFileOut.close()\n",
    "PairsFileIn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['sort', '-u', '-o', '../data/tur/steps_new/tur.all.phono.sign_sort_u', '../data/tur/steps_new/tur.all.phono.sign'], returncode=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "my_env = {'LC_COLLATE':'C'}\n",
    "\n",
    "PairsSignFile = f'../data/{Lang}/steps_new/{Lang}.all.phono.sign'\n",
    "SortedSignFile = f'../data/{Lang}/steps_new/{Lang}.all.phono.sign_sort_u'\n",
    "\n",
    "subprocess.run(['sort', '-u', '-o', SortedSignFile, PairsSignFile], env=my_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group the pairs in series in order to split them in separate files that can be processed asynchronously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SignFile = f'../data/{Lang}/steps_new/{Lang}.all.phono.sign_sort_u'\n",
    "SeriesFile = f'../data/{Lang}/steps_new/{Lang}.all.phono.series'\n",
    "\n",
    "FileIn = open(SignFile)\n",
    "FileOut = open(SeriesFile, 'w')\n",
    "\n",
    "# we keep only the pairs whose signature appears at least Min times in total\n",
    "Min = 0\n",
    "\n",
    "Pairs = {}\n",
    "CurrentSignCourte = ''\n",
    "for Line in FileIn:\n",
    "    Dist, Diff, Word1, Word2 = Line.rstrip('\\n').split('\\t')\n",
    "    Lemme1, Tag1 = Word1.split('=')\n",
    "    Lemme2, Tag2 = Word2.split('=')\n",
    "    Pair = f'{Word1}:{Word2}'\n",
    "    if Dist == '0' or Diff == '':\n",
    "        continue\n",
    "    SignCourte = f'{Dist} {Diff}'\n",
    "    SignLongue = f'{Dist} {Diff} {Tag1} {Tag2}'\n",
    "    if SignCourte == CurrentSignCourte:\n",
    "        if SignLongue not in Pairs:\n",
    "            Pairs[SignLongue] = []\n",
    "        Pairs[SignLongue].append(Pair)\n",
    "        continue\n",
    "    for Sign in Pairs:\n",
    "        if len(Pairs[Sign]) >= Min:\n",
    "            FileOut.write('{}\\t{}\\n'.format(Sign, ' '.join(Pairs[Sign])))\n",
    "    CurrentSignCourte = SignCourte\n",
    "    Pairs = {SignLongue: [Pair]}\n",
    "for Sign in Pairs:\n",
    "    if len(Pairs[Sign]) >= Min:\n",
    "        FileOut.write('{}\\t{}\\n'.format(Sign, ' '.join(Pairs[Sign])))\n",
    "FileOut.close()\n",
    "FileIn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the pairs in separate files that can be processed asynchronously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import regex\n",
    "import Levenshtein\n",
    "import collections\n",
    "from analogypatternslib import chardiff, diffsign\n",
    "\n",
    "def read_pairs(FileName):\n",
    "    '''\n",
    "    Read the form/tag pairs\n",
    "    '''\n",
    "    Pairs = {}\n",
    "    PairsFile = open(FileName)\n",
    "    for Line in PairsFile:\n",
    "        Sign, SignPairs  = Line.rstrip('\\n').split('\\t')\n",
    "        InPairs = [Pair.split(':') for Pair in SignPairs.split(' ')]\n",
    "        # print(SignMorpho, SignPairs, InPairs)\n",
    "        try:\n",
    "            for Word1, Word2 in InPairs:\n",
    "                Pairs[(Word1, Word2)] = 1\n",
    "        except:\n",
    "            print(Sign)\n",
    "            print(InPairs)\n",
    "    PairsFile.close()\n",
    "    return(Pairs)\n",
    "\n",
    "def pair_signatures(Pairs):\n",
    "    '''\n",
    "    Compute the signatures of the pairs\n",
    "    '''\n",
    "    Sign_Pairs = {}\n",
    "    # Pairs_Sign = {}\n",
    "    for Word1, Word2 in Pairs:\n",
    "        # print(Word1, Word2)\n",
    "        (Form1, Cat1) = Word1.split('=')\n",
    "        (Form2, Cat2) = Word2.split('=')\n",
    "        (DiffSign, Reg1, Reg2) = diffsign(Form1, Form2)\n",
    "        CharDiff = chardiff(Form1, Form2)\n",
    "        Dist = Levenshtein.distance(Form1, Form2, weights=(1,1,2))\n",
    "        Signature = (CharDiff, Dist, DiffSign, Reg1, Reg2, Cat1, Cat2)\n",
    "        # Pairs_Sign[(Form1, Cat1, Form2, Cat2)] = Signature\n",
    "        if Signature not in Sign_Pairs:\n",
    "            Sign_Pairs[Signature] = {}\n",
    "        Sign_Pairs[Signature][(Form1, Cat1, Form2, Cat2)] = 1\n",
    "    return(Sign_Pairs)\n",
    "\n",
    "def write_pair_signatures(Sign_Pairs, Number_of_parts, FileName):\n",
    "    '''\n",
    "    write the signatures of the pairs\n",
    "    '''\n",
    "    File = {}\n",
    "    for Index in range(Number_of_parts):\n",
    "        File[Index] = open(f'{FileName}{Index:03d}', 'w')\n",
    "    for Index, Signature in enumerate(Sign_Pairs):\n",
    "        for Pair in Sign_Pairs[Signature]:\n",
    "            Form1, Cat1, Form2, Cat2 = Pair\n",
    "            File[Index % Number_of_parts].write(f'{Form1} {Cat1} {Form2} {Cat2}\\n')\n",
    "    for Index in range(Number_of_parts):\n",
    "        File[Index].close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PairsFileInName = f'../data/{Lang}/steps_new/{Lang}.all.phono.series'\n",
    "PartsDirectory = f'../data/{Lang}/steps_new/{Lang}.parts'\n",
    "if not os.path.exists(PartsDirectory):\n",
    "    os.makedirs(PartsDirectory)\n",
    "FileNameOut = f'../data/{Lang}/steps_new/{Lang}.parts/{Lang}.all.phono.series.part_'\n",
    "\n",
    "AllPairs = read_pairs(PairsFileInName)\n",
    "Sign_Pairs = pair_signatures(AllPairs)\n",
    "write_pair_signatures(Sign_Pairs, Number_of_parts, FileNameOut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Asynchronous launch of the script that computes the patterns on all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "PartsDirectory = f'../data/{Lang}/steps_new/{Lang}.parts'\n",
    "FileNameFilter = f'{Lang}.all.phono.series.part_???'\n",
    "subprocess.Popen(['python3',\n",
    "                  'analogy_patterns_2passes_async.py',\n",
    "                  '-d', PartsDirectory,\n",
    "                  '-f', FileNameFilter,\n",
    "                  '-w', str(Workers),\n",
    "                  '-c', '1', '-n', '1', '-x', str(MaxVar)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2\n",
    "\n",
    "Concatenate the pattern files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PairsFileInName = f'../data/{Lang}/steps_new/{Lang}.parts/{Lang}.all.phono.series.part_'\n",
    "PairsFileOutName = f'../data/{Lang}/steps_new/{Lang}.all.phono.series.signs.regex-001-1-{MaxVar}'\n",
    "\n",
    "PairsFileOut = open(PairsFileOutName, 'w')\n",
    "for Index in range(Number_of_parts):\n",
    "    FileName = f'{PairsFileInName}{Index:03d}.regex-001-1-{MaxVar}'\n",
    "    FileIn = open(FileName)\n",
    "    for Line in FileIn:\n",
    "        PairsFileOut.write(Line)\n",
    "    FileIn.close()\n",
    "PairsFileOut.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of the families and series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from familylib import get_roots\n",
    "\n",
    "def read_pairs_series(FileName):\n",
    "    '''\n",
    "    Read the series\n",
    "    '''\n",
    "    Pairs = {}\n",
    "    PairsFile = open(FileName)\n",
    "    Words = {}\n",
    "    for Line in PairsFile:\n",
    "        _Sign, SignPairs  = Line.rstrip('\\n').split('\\t')\n",
    "        InPairs = [Pair.split(':') for Pair in SignPairs.split(' ')]\n",
    "        for Word1, Word2 in InPairs:\n",
    "            Lemma1, _Cat1 = Word1.split('=')\n",
    "            Lemma2, _Cat2 = Word2.split('=')\n",
    "            if Lemma1 not in Words:\n",
    "                Words[Lemma1] = []\n",
    "            Words[Lemma1].append(Word1)\n",
    "            if Lemma2 not in Words:\n",
    "                Words[Lemma2] = []\n",
    "            Words[Lemma2].append(Word2)\n",
    "            if Word1 not in Pairs:\n",
    "                Pairs[Word1] = []\n",
    "            if Word2 not in Pairs:\n",
    "                Pairs[Word2] = []\n",
    "            if Word2 not in Pairs[Word1]:\n",
    "                Pairs[Word1].append(Word2)\n",
    "    PairsFile.close()\n",
    "    for Lemma in Words:\n",
    "        for Word in Words[Lemma]:\n",
    "            Pairs[Word] += [W for W in Words[Lemma] if W != Word]\n",
    "    return(Pairs)\n",
    "\n",
    "def read_pairs_regex(FileName):\n",
    "    '''\n",
    "    Read the patterns\n",
    "    '''\n",
    "    Pairs = {}\n",
    "    Tags = {}\n",
    "    PairsFile = open(FileName)\n",
    "    for Line in PairsFile:\n",
    "        Mot1, Cat1, Mot2, Cat2, RegExIn, RegExOut, RegEx1, RegEx2, Radical = Line.rstrip('\\n').split('\\t')\n",
    "        Word1 = f'{Mot1}={Cat1}'\n",
    "        Word2 = f'{Mot2}={Cat2}'\n",
    "        if (Word1, Word2) not in Tags:\n",
    "            Tags[(Word1, Word2)] = []\n",
    "        Tags[(Word1, Word2)].append((RegEx1, RegEx2))\n",
    "        if Word1 not in Pairs:\n",
    "            Pairs[Word1] = []\n",
    "        if Word2 not in Pairs:\n",
    "            Pairs[Word2] = []\n",
    "        if Word2 not in Pairs[Word1]:\n",
    "            Pairs[Word1].append(Word2)\n",
    "    PairsFile.close()\n",
    "    return(Pairs, Tags)\n",
    "\n",
    "SeriesFile = f'../data/{Lang}/steps_new/{Lang}.all.phono.series'\n",
    "SeriesPairs = read_pairs_series(SeriesFile)\n",
    "SeriesFamilies, SeriesFamiliesEdges = get_roots(SeriesPairs)\n",
    "PairsFileInName = f'../data/{Lang}/steps_new/{Lang}.all.phono.series.signs.regex-001-1-{MaxVar}'\n",
    "Pairs, Tags = read_pairs_regex(PairsFileInName)\n",
    "\n",
    "Families, FamiliesEdges = get_roots(Pairs)\n",
    "FamiliesEdgesLength = sorted([(len(Family), Root, Family) for Root, Family in FamiliesEdges.items()], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PairsFamiliesFile = open(f'../data/{Lang}/steps_new/{Lang}.all.phono.series.signs.regex-001-1-{MaxVar}.families', 'w')\n",
    "PairsSeriesFile = open(f'../data/{Lang}/steps_new/{Lang}.all.phono.series.signs.regex-001-1-{MaxVar}.series', 'w')\n",
    "\n",
    "for Length, Root, Family in FamiliesEdgesLength:\n",
    "    PairsFamiliesFile.write('{}\\n'.format(' '.join([f'{W1}:{W2}' for W1, W2 in sorted(FamiliesEdges[Root])])))\n",
    "\n",
    "    for W1, W2 in Family:\n",
    "        TagsList = ' '.join(['='.join(list(T)) for T in Tags[(W1, W2)]])\n",
    "        PairsSeriesFile.write(f'{W1}\\t{W2}\\t{TagsList}\\n')\n",
    "    PairsSeriesFile.write('\\n')\n",
    "\n",
    "PairsSeriesFile.close()\n",
    "PairsFamiliesFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FAP selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_series_edges(SeriesFileName):\n",
    "    # dictionary of pattern connections without categoies. Value is the cumulated size of the connecting relations\n",
    "    PatternConnections = {}\n",
    "    # dictionary of pattern connections with categories. Value is the cumulated size of the connecting relations\n",
    "    PatternConnectionsCat = {}\n",
    "    SeriesFile = open(SeriesFileName)\n",
    "    for Line in SeriesFile:\n",
    "        Line = Line.rstrip('\\n')\n",
    "        if not Line:\n",
    "            continue\n",
    "        Word1, Word2, TagList = Line.split('\\t')\n",
    "        Lemma1, Cat1 = Word1.split('=')\n",
    "        Lemma2, Cat2 = Word2.split('=')\n",
    "        TagList = TagList.split(' ')\n",
    "        TagList = [tuple(Desc.split('=')) for Desc in TagList]\n",
    "        for PatternWord1, PatternWord2 in TagList:\n",
    "            Pattern = (PatternWord1, PatternWord2)\n",
    "            Pattern1 = PatternWord1\n",
    "            Pattern2 = PatternWord2\n",
    "            if Pattern1 not in PatternConnections:\n",
    "                PatternConnections[Pattern1] = 0\n",
    "            PatternConnections[Pattern1] += 1\n",
    "            if Pattern2 not in PatternConnections:\n",
    "                PatternConnections[Pattern2] = 0\n",
    "            PatternConnections[Pattern2] += 1\n",
    "            PatternCat = (PatternWord1, Cat1, PatternWord2, Cat2)\n",
    "            Pattern1Cat = (PatternWord1, Cat1)\n",
    "            Pattern2Cat = (PatternWord2, Cat2)\n",
    "            if Pattern1Cat not in PatternConnectionsCat:\n",
    "                PatternConnectionsCat[Pattern1Cat] = 0\n",
    "            PatternConnectionsCat[Pattern1Cat] += 1\n",
    "            if Pattern2Cat not in PatternConnectionsCat:\n",
    "                PatternConnectionsCat[Pattern2Cat] = 0\n",
    "            PatternConnectionsCat[Pattern2Cat] += 1\n",
    "    return(PatternConnections, PatternConnectionsCat)\n",
    "\n",
    "import regex\n",
    "\n",
    "def select_patterns(SeriesFileName, FAP_FileName, PatternConnections, PatternConnectionsCat):\n",
    "    SeriesFile = open(SeriesFileName)\n",
    "    FAP_File = open(FAP_FileName, 'w')\n",
    "    for Line in SeriesFile:\n",
    "        Line = Line.rstrip('\\n')\n",
    "        if not Line:\n",
    "            continue\n",
    "        Word1, Word2, TagList = Line.split('\\t')\n",
    "        Lemma1, Cat1 = Word1.split('=')\n",
    "        Lemma2, Cat2 = Word2.split('=')\n",
    "        TagList = TagList.split(' ')\n",
    "        TagList = [tuple(Desc.split('=')) for Desc in TagList]\n",
    "        AllPatternConnections = []\n",
    "        AllPatternConnectionsCat = []\n",
    "        for PatternWord1, PatternWord2 in TagList:\n",
    "            Pattern = (PatternWord1, PatternWord2)\n",
    "            Pattern1 = PatternWord1\n",
    "            Pattern2 = PatternWord2\n",
    "            AllPatternConnections.append((PatternConnections[Pattern1] + PatternConnections[Pattern2], PatternWord1, Cat1, PatternWord2, Cat2))\n",
    "            PatternCat = (PatternWord1, Cat1, PatternWord2, Cat2)\n",
    "            Pattern1Cat = (PatternWord1, Cat1)\n",
    "            Pattern2Cat = (PatternWord2, Cat2)\n",
    "            AllPatternConnectionsCat.append((PatternConnectionsCat[Pattern1Cat] + PatternConnectionsCat[Pattern2Cat], PatternWord1, Cat1, PatternWord2, Cat2))\n",
    "        BestPatternConnections = sorted(AllPatternConnections, reverse=True)\n",
    "        Connections, Patt1, C1, Patt2, C2 = BestPatternConnections[0]\n",
    "        BestPatternConnectionsCat = sorted(AllPatternConnectionsCat, reverse=True)\n",
    "        ConnectionsCat, Patt1Cat, C1Cat, Patt2Cat, C2Cat = BestPatternConnectionsCat[0]\n",
    "        if (Patt1 == '^(.+)$' and regex.match('\\^[^(]+\\(\\.\\+\\)\\$', Patt2)) or (Patt2 == '^(.+)$' and regex.match('\\^[^(]+\\(\\.\\+\\)\\$', Patt1)):\n",
    "            BestPatt = (Patt1, Patt2)\n",
    "        else:\n",
    "            BestPatt = (Patt1Cat, Patt2Cat)\n",
    "        FAP_File.write(f'{Word1}\\t{Word2}\\t{BestPatt[0]}\\t{Cat1}\\t{BestPatt[1]}\\t{Cat2}\\n')\n",
    "    FAP_File.close()    \n",
    "    SeriesFile.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SeriesFileIn = f'../data/{Lang}/steps_new/{Lang}.all.phono.series.signs.regex-001-1-{MaxVar}.series'\n",
    "FAP_FileOut = f'../data/{Lang}/steps_new/{Lang}.all.phono.FAP'\n",
    "PatternConnections, PatternConnectionsCat = read_series_edges(SeriesFileIn)\n",
    "select_patterns(SeriesFileIn, FAP_FileOut, PatternConnections, PatternConnectionsCat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy of annotations in the initial files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduced_pattern(Pattern):\n",
    "    ReducedPattern = Pattern\n",
    "    ReducedPattern = ReducedPattern.replace('^', '')\n",
    "    ReducedPattern = ReducedPattern.replace('$', '')\n",
    "    ReducedPattern = ReducedPattern.replace('(.+)', '+')\n",
    "    ReducedPattern = ReducedPattern.replace('\\\\1', '+')\n",
    "    ReducedPattern = ReducedPattern.replace('\\\\2', '+')\n",
    "    return(ReducedPattern)\n",
    "\n",
    "def read_best_series(FAP_FileName):\n",
    "    FAP_File = open(FAP_FileName)\n",
    "    FAP = {}\n",
    "    for Line in FAP_File:\n",
    "        Line = Line.rstrip('\\n')\n",
    "        if not Line:\n",
    "            continue\n",
    "        Word1, Word2, Pattern1, Cat1, Pattern2, Cat2 = Line.split('\\t')\n",
    "        Pattern1 = reduced_pattern(Pattern1)\n",
    "        Pattern2 = reduced_pattern(Pattern2)\n",
    "        FAP[(Word1, Word2)] = (f'{Pattern1}/{Pattern2}')\n",
    "    FAP_File.close()\n",
    "    return(FAP)\n",
    "\n",
    "from analogypatternslib import diffpattern\n",
    "\n",
    "def complement_data(InFileName, OutFileName, FAP):\n",
    "    InFile = open(InFileName)\n",
    "    OutFile = open(OutFileName, 'w')\n",
    "    for Line in InFile:\n",
    "        Line = Line.rstrip('\\n')\n",
    "        PhonoLem, PhonoForm, Tag, OrthoLem, OrthoForm, PhonoLem1, PhonoForm1, RedTag = Line.split('\\t')\n",
    "        Word1 = f'{PhonoLem1}=V;NFIN'\n",
    "        Word2 = f'{PhonoForm1}={RedTag}'\n",
    "        if (Word1, Word2) in FAP:\n",
    "            Patts = FAP[(Word1, Word2)]\n",
    "            OutFile.write(f'{Line}\\t{Patts}\\n')\n",
    "        elif PhonoLem1 == PhonoForm1:\n",
    "            OutFile.write(f'{Line}\\t+/+\\n')\n",
    "        else:\n",
    "            _E, Patt1, Patt2 = diffpattern(PhonoLem1, PhonoForm1)\n",
    "            Patt1r = reduced_pattern(Patt1)\n",
    "            Patt2r = reduced_pattern(Patt2)\n",
    "            Patt = f'{Patt1r}/{Patt2r}'\n",
    "            OutFile.write(f'{Line}\\t{Patt}\\n')\n",
    "    OutFile.close()\n",
    "    InFile.close()\n",
    "    return\n",
    "\n",
    "def complement_data_judgements_dev(InFileName, OutFileName, FAP):\n",
    "    InFile = open(InFileName)\n",
    "    OutFile = open(OutFileName, 'w')\n",
    "    for Line in InFile:\n",
    "        Line = Line.rstrip('\\n')\n",
    "        PhonoLem, PhonoForm, Tag, Judgement, PhonoLem1, PhonoForm1, RedTag = Line.split('\\t')\n",
    "        Word1 = f'{PhonoLem1}=V;NFIN'\n",
    "        Word2 = f'{PhonoForm1}={RedTag}'\n",
    "        if (Word1, Word2) in FAP:\n",
    "            Patts = FAP[(Word1, Word2)]\n",
    "            OutFile.write(f'{Line}\\t{Patts}\\n')\n",
    "        elif PhonoLem1 == PhonoForm1:\n",
    "            OutFile.write(f'{Line}\\t+/+\\n')\n",
    "        else:\n",
    "            _E, Patt1, Patt2 = diffpattern(PhonoLem1, PhonoForm1)\n",
    "            Patt1r = reduced_pattern(Patt1)\n",
    "            Patt2r = reduced_pattern(Patt2)\n",
    "            Patt = f'{Patt1r}/{Patt2r}'\n",
    "            OutFile.write(f'{Line}\\t{Patt}\\n')\n",
    "    OutFile.close()\n",
    "    InFile.close()\n",
    "    return\n",
    "\n",
    "def complement_data_judgements_tst(InFileName, OutFileName, FAP):\n",
    "    InFile = open(InFileName)\n",
    "    OutFile = open(OutFileName, 'w')\n",
    "    for Line in InFile:\n",
    "        Line = Line.rstrip('\\n')\n",
    "        PhonoLem, PhonoForm, Tag, PhonoLem1, PhonoForm1, RedTag = Line.split('\\t')\n",
    "        Word1 = f'{PhonoLem1}=V;NFIN'\n",
    "        Word2 = f'{PhonoForm1}={RedTag}'\n",
    "        if (Word1, Word2) in FAP:\n",
    "            Patts = FAP[(Word1, Word2)]\n",
    "            OutFile.write(f'{Line}\\t{Patts}\\n')\n",
    "        elif PhonoLem1 == PhonoForm1:\n",
    "            OutFile.write(f'{Line}\\t+/+\\n')\n",
    "        else:\n",
    "            _E, Patt1, Patt2 = diffpattern(PhonoLem1, PhonoForm1)\n",
    "            Patt1r = reduced_pattern(Patt1)\n",
    "            Patt2r = reduced_pattern(Patt2)\n",
    "            Patt = f'{Patt1r}/{Patt2r}'\n",
    "            OutFile.write(f'{Line}\\t{Patt}\\n')\n",
    "    OutFile.close()\n",
    "    InFile.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FAP_FileName = f'../data/{Lang}/steps_new/{Lang}.all.phono.FAP'\n",
    "FAP = read_best_series(FAP_FileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "InFileName1 = f'../data/{Lang}/steps_new/{Lang}.trn.phono.pairs'\n",
    "OutFileName1 = f'../data/{Lang}/patterns/{Lang}.trn.phono.patterns'\n",
    "complement_data(InFileName1, OutFileName1, FAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "InFileName2 = f'../data/{Lang}/steps_new/{Lang}.dev.phono.pairs'\n",
    "OutFileName2 = f'../data/{Lang}/patterns/{Lang}.dev.phono.patterns'\n",
    "complement_data(InFileName2, OutFileName2, FAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Lang != \"tam\":\n",
    "    InFileName3 = f'../data/{Lang}/steps_new/{Lang}.tst.phono.pairs'\n",
    "    OutFileName3 = f'../data/{Lang}/patterns/{Lang}.tst.phono.patterns'\n",
    "    complement_data(InFileName3, OutFileName3, FAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "InFileName4 = f'../data/{Lang}/steps_new/{Lang}.nonce_full.phono.pairs'\n",
    "OutFileName4 = f'../data/{Lang}/patterns/{Lang}.nonce_full.phono.patterns'\n",
    "complement_data(InFileName4, OutFileName4, FAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
